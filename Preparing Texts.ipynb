{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the Natural Language Toolkit (NLTK) to prepare a text. (And this afternoon to do some analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we will import the texts from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tell it where we want the text to come from. If you don't know the path to your UNC files, right click the file and see its location. My files are on my desktop. For this notebook to work, you'll need to click into the cell below and change the root location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_root = '/Users/senderle/Dropbox/Shared/cwp/nasn/input-texts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to read in the files from that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists = PlaintextCorpusReader(corpus_root,  '.*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we have the files we want by asking for the file ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['church-hatcher-hatcher.txt',\n",
       " 'fpn-ball-ball.txt',\n",
       " 'fpn-brownw-brown.txt',\n",
       " 'fpn-bruce-bruce.txt',\n",
       " 'fpn-burton-burton.txt',\n",
       " 'fpn-burtont-burton.txt',\n",
       " 'fpn-ferebee-ferebee.txt',\n",
       " 'fpn-grandy-grandy.txt',\n",
       " 'fpn-hortonlife-horton.txt',\n",
       " 'fpn-hortonpoem-hortonpoem.txt',\n",
       " 'fpn-hughes-hughes.txt',\n",
       " 'fpn-jackson-jackson.txt',\n",
       " 'fpn-jacobs-jacobs.txt',\n",
       " 'fpn-jones-jones.txt',\n",
       " 'fpn-lane-lane.txt',\n",
       " 'fpn-mason-mason.txt',\n",
       " 'fpn-northup-northup.txt',\n",
       " 'fpn-robinson-robinson.txt',\n",
       " 'fpn-roper-roper.txt',\n",
       " 'fpn-steward-steward.txt',\n",
       " 'fpn-veney-veney.txt',\n",
       " 'fpn-washeducation-washing.txt',\n",
       " 'fpn-washington-washing.txt',\n",
       " 'fpn-williams-williams.txt',\n",
       " 'nc-jones85-jones85.txt',\n",
       " 'nc-omarsaid-omarsaid.txt',\n",
       " 'neh-aaron-aaron.txt',\n",
       " 'neh-adams-adams.txt',\n",
       " 'neh-adamsh-adamsh.txt',\n",
       " 'neh-aga-aga.txt',\n",
       " 'neh-albert-albert.txt',\n",
       " 'neh-aleckson-aleckson.txt',\n",
       " 'neh-alexander-alexander.txt',\n",
       " 'neh-allen-allen.txt',\n",
       " 'neh-allinson-allinson.txt',\n",
       " 'neh-anderson-anderson.txt',\n",
       " 'neh-andersonr-andersonr.txt',\n",
       " 'neh-andersonw-andersonw.txt',\n",
       " 'neh-andersrob-andersrob.txt',\n",
       " 'neh-armistead-armistead.txt',\n",
       " 'neh-arter-arter.txt',\n",
       " 'neh-arthur-arthur.txt',\n",
       " 'neh-auntjudy-auntjudy.txt',\n",
       " 'neh-ballslavery-ball.txt',\n",
       " 'neh-baquaqua-baquaqua.txt',\n",
       " 'neh-barber-barber.txt',\n",
       " 'neh-barrett-barrett.txt',\n",
       " 'neh-bayley-bayley.txt',\n",
       " 'neh-beard63-beard63.txt',\n",
       " 'neh-beardj-beard.txt',\n",
       " 'neh-bethune-bethune.txt',\n",
       " 'neh-bibb-bibb.txt',\n",
       " 'neh-black-black.txt',\n",
       " 'neh-blair-blair.txt',\n",
       " 'neh-bleby-bleby.txt',\n",
       " 'neh-bluett-bluett.txt',\n",
       " 'neh-boen-boen.txt',\n",
       " 'neh-boxbrown-boxbrown.txt',\n",
       " 'neh-bradford-bradford.txt',\n",
       " 'neh-bragg-bragg.txt',\n",
       " 'neh-bragg1915-bragg1915.txt',\n",
       " 'neh-branham-branham.txt',\n",
       " 'neh-brinch-brinch.txt',\n",
       " 'neh-brown47-brown47.txt',\n",
       " 'neh-brown52-brown52.txt',\n",
       " 'neh-brown55-brown55.txt',\n",
       " 'neh-brown80-brown80.txt',\n",
       " 'neh-brownbox-brownbox.txt',\n",
       " 'neh-browne-browne.txt',\n",
       " 'neh-brownhal-brownhal.txt',\n",
       " 'neh-brownj-brownj.txt',\n",
       " 'neh-brownrw-brownrw.txt',\n",
       " 'neh-brownsn-brownsn.txt',\n",
       " 'neh-brownww-brown.txt',\n",
       " 'neh-bruceje-bruceje.txt',\n",
       " 'neh-bruner-bruner.txt',\n",
       " 'neh-campbell-campbell.txt',\n",
       " 'neh-capehart-capehart.txt',\n",
       " 'neh-captain-captain.txt',\n",
       " 'neh-carolinatwin-carolinatwin.txt',\n",
       " 'neh-charlton-charlton.txt',\n",
       " 'neh-chesnutt-chesnutt.txt',\n",
       " 'neh-clarke-clarke.txt',\n",
       " 'neh-clarkes-clarkes.txt',\n",
       " 'neh-clement-clement.txt',\n",
       " 'neh-cox-cox.txt',\n",
       " 'neh-craft-craft.txt',\n",
       " 'neh-cugoano-cugoano.txt',\n",
       " 'neh-curry-curry.txt',\n",
       " 'neh-davisn-davis.txt',\n",
       " 'neh-delaney-delaney.txt',\n",
       " 'neh-detroit-detroit.txt',\n",
       " 'neh-doug1906-doug1906.txt',\n",
       " 'neh-dougl92-dougl92.txt',\n",
       " 'neh-douglass-douglass.txt',\n",
       " 'neh-douglass1853-douglass1853.txt',\n",
       " 'neh-douglass55-douglass55.txt',\n",
       " 'neh-douglasslife-douglass.txt',\n",
       " 'neh-drew-drew.txt',\n",
       " 'neh-drumgoold-drumgoold.txt',\n",
       " 'neh-dsmith-dsmith.txt',\n",
       " 'neh-early-early.txt',\n",
       " 'neh-edwardsc-edwards.txt',\n",
       " 'neh-edwardsj-edwardsj.txt',\n",
       " 'neh-eldridge-eldridge.txt',\n",
       " 'neh-eliot-eliot.txt',\n",
       " 'neh-eliza1-eliza1.txt',\n",
       " 'neh-eliza2-eliza2.txt',\n",
       " 'neh-equiano1-equiano1.txt',\n",
       " 'neh-equiano2-equiano2.txt',\n",
       " 'neh-fedric-fedric.txt',\n",
       " 'neh-ferrill-ferrill.txt',\n",
       " 'neh-fields-fields.txt',\n",
       " 'neh-fjones-jones.txt',\n",
       " 'neh-fleming-fleming.txt',\n",
       " 'neh-flipper-flipper.txt',\n",
       " 'neh-floyd-floyd.txt',\n",
       " 'neh-fortis-fortis.txt',\n",
       " 'neh-foster-foster.txt',\n",
       " 'neh-franklin-franklin.txt',\n",
       " 'neh-frederick-frederick.txt',\n",
       " 'neh-gaines-gaines.txt',\n",
       " 'neh-gallaudet-gallaudet.txt',\n",
       " 'neh-garlick-garlick.txt',\n",
       " 'neh-greena-greena.txt',\n",
       " 'neh-greenew-greenew.txt',\n",
       " 'neh-greenjd-greenjd.txt',\n",
       " 'neh-greenw-greenw.txt',\n",
       " 'neh-gregory-gregory.txt',\n",
       " 'neh-griest-griest.txt',\n",
       " 'neh-grimes25-grimes25.txt',\n",
       " 'neh-grimes55-grimes55.txt',\n",
       " 'neh-griswold-griswold.txt',\n",
       " 'neh-gronniosaw-gronnios.txt',\n",
       " 'neh-gurley-gurley.txt',\n",
       " 'neh-hall-hall.txt',\n",
       " 'neh-hammon-hammon.txt',\n",
       " 'neh-hammond-hammond.txt',\n",
       " 'neh-harriet-harriet.txt',\n",
       " 'neh-hawkins-hawkins.txt',\n",
       " 'neh-hayden-hayden.txt',\n",
       " 'neh-heard-heard.txt',\n",
       " 'neh-henderson-henderson.txt',\n",
       " 'neh-henry-henry.txt',\n",
       " 'neh-henryg-henryg.txt',\n",
       " 'neh-henson-henson.txt',\n",
       " 'neh-henson49-henson49.txt',\n",
       " 'neh-henson58-henson58.txt',\n",
       " 'neh-henson81-henson81.txt',\n",
       " 'neh-heth-heth.txt',\n",
       " 'neh-hildreth-hildreth.txt',\n",
       " 'neh-holland-holland.txt',\n",
       " 'neh-holley-holley.txt',\n",
       " 'neh-holsey-holsey.txt',\n",
       " 'neh-hopper-hopper.txt',\n",
       " 'neh-iwilliams-iwilliams.txt',\n",
       " 'neh-jacksona-jacksona.txt',\n",
       " 'neh-jacksonc-jackson.txt',\n",
       " 'neh-jacksonm-jackson.txt',\n",
       " 'neh-jamesth-jamesth.txt',\n",
       " 'neh-jamison-jamison.txt',\n",
       " 'neh-jasper-jasper.txt',\n",
       " 'neh-jbrown-jbrown.txt',\n",
       " 'neh-jeajohn-jeajohn.txt',\n",
       " 'neh-jennings-jennings.txt',\n",
       " 'neh-jeter-jeter.txt',\n",
       " 'neh-jjacobs-jjacobs.txt',\n",
       " 'neh-jjoseph-jjoseph.txt',\n",
       " 'neh-johnson-johnson.txt',\n",
       " 'neh-johnson1-johnson.txt',\n",
       " 'neh-johnsontl-johnsontl.txt',\n",
       " 'neh-johnstone-johnstone.txt',\n",
       " 'neh-jonestom-jones.txt',\n",
       " 'neh-joyce-joyce.txt',\n",
       " 'neh-keckley-keckley.txt',\n",
       " 'neh-kelley-kelley.txt',\n",
       " 'neh-lanelunsford-lane.txt',\n",
       " 'neh-latta-latta.txt',\n",
       " 'neh-leehf-leehf.txt',\n",
       " 'neh-leewilliam-lee.txt',\n",
       " 'neh-lester-lester.txt',\n",
       " 'neh-levering-levering.txt',\n",
       " 'neh-lewisj-lewisj.txt',\n",
       " 'neh-lewisjw-lewisjw.txt',\n",
       " 'neh-lintner-lintner.txt',\n",
       " 'neh-loguen-loguen.txt',\n",
       " 'neh-long-long.txt',\n",
       " 'neh-lowery-lowery.txt',\n",
       " 'neh-mallory-mallory.txt',\n",
       " 'neh-manzano-manzano.txt',\n",
       " 'neh-marrs-marrs.txt',\n",
       " 'neh-mars-mars.txt',\n",
       " 'neh-mars64-mars64.txt',\n",
       " 'neh-maysamuel-maysamuel.txt',\n",
       " 'neh-mccray-mary.txt',\n",
       " 'neh-mcpherson-mcpherson.txt',\n",
       " 'neh-meachum-meachum.txt',\n",
       " 'neh-merritt-merritt.txt',\n",
       " 'neh-millie-christine-millie-christine.txt',\n",
       " 'neh-mitchell-mitchell.txt',\n",
       " 'neh-moore1-moore1.txt',\n",
       " 'neh-moore2-moore2.txt',\n",
       " 'neh-mott-mott.txt',\n",
       " 'neh-mott26-mott26.txt',\n",
       " 'neh-mountain-mountain.txt',\n",
       " 'neh-natlove-natlove.txt',\n",
       " 'neh-neilson-neilson.txt',\n",
       " 'neh-nell-nell.txt',\n",
       " 'neh-nicholson-nicholson.txt',\n",
       " 'neh-norris-norris.txt',\n",
       " 'neh-offley-offley.txt',\n",
       " 'neh-oneal-oneal.txt',\n",
       " 'neh-parker-parker.txt',\n",
       " 'neh-parker1-parker.txt',\n",
       " 'neh-parkerh-parkerh.txt',\n",
       " 'neh-pendleton-pendle.txt',\n",
       " 'neh-penning-penning.txt',\n",
       " 'neh-penning49-penning49.txt',\n",
       " 'neh-peterson-peterson.txt',\n",
       " 'neh-pickard-pickard.txt',\n",
       " 'neh-picquet-picquet.txt',\n",
       " 'neh-pierson-pierson.txt',\n",
       " 'neh-platt-platt.txt',\n",
       " 'neh-pomp-pomp.txt',\n",
       " 'neh-prince-prince.txt',\n",
       " 'neh-randol55-randol55.txt',\n",
       " 'neh-randolph-randolph.txt',\n",
       " 'neh-rayemma-rayemma.txt',\n",
       " 'neh-richmond-richmond.txt',\n",
       " 'neh-robert-robert.txt',\n",
       " 'neh-roberts-roberts.txt',\n",
       " 'neh-robinsonn-robinson.txt',\n",
       " 'neh-roper-roper.txt',\n",
       " 'neh-royal-royal.txt',\n",
       " 'neh-rudd-rudd.txt',\n",
       " 'neh-runaway-runaway.txt',\n",
       " 'neh-said-said.txt',\n",
       " 'neh-sally-sally.txt',\n",
       " 'neh-sancho1-sancho1.txt',\n",
       " 'neh-sancho2-sancho2.txt',\n",
       " 'neh-scott-scott.txt',\n",
       " 'neh-simmons-simmons.txt',\n",
       " 'neh-simpson-simpson.txt',\n",
       " 'neh-singleton-singleton.txt',\n",
       " 'neh-slaveryillus-slaveryillus.txt',\n",
       " 'neh-smallwood-smallwood.txt',\n",
       " 'neh-smitham-smith.txt',\n",
       " 'neh-smithhar-smithhar.txt',\n",
       " 'neh-smithj-smithj.txt',\n",
       " 'neh-smithste-smithste.txt',\n",
       " 'neh-stedman-stedman.txt',\n",
       " 'neh-stevens-stevens.txt',\n",
       " 'neh-story-story.txt',\n",
       " 'neh-straker-straker.txt',\n",
       " 'neh-stroyer-stroyer.txt',\n",
       " 'neh-stroyer85-stroyer85.txt',\n",
       " 'neh-suggs-suggs.txt',\n",
       " 'neh-taylor-taylor.txt',\n",
       " 'neh-taylorsu-taylorsu.txt',\n",
       " 'neh-thatcher-thatcher.txt',\n",
       " 'neh-thompsch-thompsch.txt',\n",
       " 'neh-thompson-thompson.txt',\n",
       " 'neh-thompson1-thompson.txt',\n",
       " 'neh-tilmon-tilmon.txt',\n",
       " 'neh-troy-troy.txt',\n",
       " 'neh-truth50-truth50.txt',\n",
       " 'neh-truth75-truth75.txt',\n",
       " 'neh-truth84-truth84.txt',\n",
       " 'neh-tubbee-tubbee.txt',\n",
       " 'neh-tubbee1848-tubbee1848.txt',\n",
       " 'neh-turner-turner.txt',\n",
       " 'neh-twain-twain.txt',\n",
       " 'neh-twelvetr-twelvetr.txt',\n",
       " 'neh-upham-upham.txt',\n",
       " 'neh-vale-vale.txt',\n",
       " 'neh-venture-venture.txt',\n",
       " 'neh-venture2-venture2.txt',\n",
       " 'neh-walters-walters.txt',\n",
       " 'neh-wards-ward.txt',\n",
       " 'neh-warner-warner.txt',\n",
       " 'neh-washstory-washin.txt',\n",
       " 'neh-watkin52-watkin52.txt',\n",
       " 'neh-watkins-watkins.txt',\n",
       " 'neh-watson-watson.txt',\n",
       " 'neh-webb-webb.txt',\n",
       " 'neh-webster-webster.txt',\n",
       " 'neh-weld-weld.txt',\n",
       " 'neh-wheatley-wheatley.txt',\n",
       " 'neh-white-white.txt',\n",
       " 'neh-whitegeo-whitegeo.txt',\n",
       " 'neh-wickham-wickham.txt',\n",
       " 'neh-wilkerson-wilkerson.txt',\n",
       " 'neh-williams-williams.txt',\n",
       " 'neh-williamsjames-williams.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlists.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use NLTK to read in text, it does the work of tokenizing (turning strings with spaces between into \"words\"). We can see this by using the \"words\" function.  (There are other functions, like sentences -- \"sents\", as well.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THIS', 'book', 'was', 'composed', 'by', 'WILLIAM', ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlists.words('neh-webb-webb.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a list of these words to use with other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "webb = wordlists.words('neh-webb-webb.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THIS',\n",
       " 'book',\n",
       " 'was',\n",
       " 'composed',\n",
       " 'by',\n",
       " 'WILLIAM',\n",
       " 'WEBB',\n",
       " ',',\n",
       " 'and',\n",
       " 'written',\n",
       " 'by',\n",
       " 'his',\n",
       " 'wife',\n",
       " ',',\n",
       " 'containing',\n",
       " 'the',\n",
       " 'life',\n",
       " 'he',\n",
       " 'has',\n",
       " 'went']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webb[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this awesome list of words has a few idiosnycracies that might change our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webb.count('THIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webb.count('this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webb.count('This')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first thing we want to do is make make THIS, this, and This all into this.  To do this we will take every text in the corpus -- in their wordlist form -- and lowercase them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "webblow = [w.lower() for w in webb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'was',\n",
       " 'composed',\n",
       " 'by',\n",
       " 'william',\n",
       " 'webb',\n",
       " ',',\n",
       " 'and',\n",
       " 'written',\n",
       " 'by',\n",
       " 'his',\n",
       " 'wife',\n",
       " ',',\n",
       " 'containing',\n",
       " 'the',\n",
       " 'life',\n",
       " 'he',\n",
       " 'has',\n",
       " 'went']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webblow[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webblow.count('this')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also want to remove the punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "webbclean = [w for w in webblow if w.isalpha() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book',\n",
       " 'was',\n",
       " 'composed',\n",
       " 'by',\n",
       " 'william',\n",
       " 'webb',\n",
       " 'and',\n",
       " 'written',\n",
       " 'by',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'containing',\n",
       " 'the',\n",
       " 'life',\n",
       " 'he',\n",
       " 'has',\n",
       " 'went',\n",
       " 'through',\n",
       " 'his']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbclean[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = wordlists.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_corpus = [w.lower() for w in words if w.lower() not in eng_stopwords and w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image',\n",
       " 'spine',\n",
       " 'image',\n",
       " 'john',\n",
       " 'jasper',\n",
       " 'frontispiece',\n",
       " 'image',\n",
       " 'title',\n",
       " 'page',\n",
       " 'image',\n",
       " 'title',\n",
       " 'page',\n",
       " 'verso',\n",
       " 'image',\n",
       " 'contents',\n",
       " 'illustrations',\n",
       " 'introduction',\n",
       " 'reader',\n",
       " 'stay']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have reached the end of preparing texts. \n",
    "We will return to this notebook in order to do some work with analyzing texts this afternoon!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back!  Now we are going to do some simple analysis with NLTK. \n",
    "\n",
    "First, how long is our text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(webbclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5397959"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How diverse is the vocabulary in our texts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text): \n",
    "...     return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012332809493365918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06797858571596659"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(webb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13553580412544022"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(wordlists.words('neh-craft-craft.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to make a frequency distribution table. This is a count of each time a word occurs in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdistwebb = FreqDist(webb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1911),\n",
       " ('I', 1770),\n",
       " ('the', 1478),\n",
       " ('.', 1403),\n",
       " ('and', 1231),\n",
       " ('to', 1201),\n",
       " ('was', 589),\n",
       " ('that', 562),\n",
       " ('a', 546),\n",
       " ('me', 472),\n",
       " ('in', 452),\n",
       " ('of', 437),\n",
       " ('had', 405),\n",
       " ('he', 357),\n",
       " ('it', 355),\n",
       " ('they', 326),\n",
       " ('would', 276),\n",
       " ('for', 269),\n",
       " ('told', 262),\n",
       " ('them', 245)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistwebb.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdistcorpus = FreqDist(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', 41109),\n",
       " ('would', 38655),\n",
       " ('man', 27246),\n",
       " ('time', 25739),\n",
       " ('said', 24563),\n",
       " ('could', 23764),\n",
       " ('mr', 22791),\n",
       " ('upon', 19182),\n",
       " ('people', 17568),\n",
       " ('day', 17227),\n",
       " ('made', 17070),\n",
       " ('men', 16892),\n",
       " ('great', 16320),\n",
       " ('slave', 16211),\n",
       " ('us', 15682),\n",
       " ('master', 15502),\n",
       " ('many', 15078),\n",
       " ('good', 15054),\n",
       " ('god', 15025),\n",
       " ('well', 14824)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistcorpus.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21683"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdistcorpus.hapaxes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to add some metadata and then add conditions to our frequency distribution table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "metadata_path = '/Users/senderle/Dropbox/Shared/cwp/nasn/North American Slave Narratives 2016-05-09 - Main Data.csv'\n",
    "with open(metadata_path) as metadata_file:\n",
    "    metadata_reader = csv.DictReader(metadata_file)\n",
    "    metadata = list(metadata_reader)\n",
    "gender_map = {row['Filename']: row['Sex'] for row in metadata}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have out metadata in and mapped, we will make the conditional frequency distribution. (You'll see that we are also cleaning the corpus in the process.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_conditional_freq = nltk.ConditionalFreqDist((gender_map[fid], w.lower()) \n",
    "                                                   for fid in wordlists.fileids() \n",
    "                                                   for w in wordlists.words(fid)\n",
    "                                                   if w.lower() not in eng_stopwords and w.isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words used by authors classified as male vs. authors classified as female?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', 34058),\n",
       " ('would', 31600),\n",
       " ('man', 24449),\n",
       " ('time', 21388),\n",
       " ('mr', 19580),\n",
       " ('could', 19372),\n",
       " ('said', 18578),\n",
       " ('upon', 16411),\n",
       " ('men', 15272),\n",
       " ('people', 14676),\n",
       " ('made', 14666),\n",
       " ('slave', 14654),\n",
       " ('day', 14222),\n",
       " ('great', 13879),\n",
       " ('master', 13288),\n",
       " ('us', 12870),\n",
       " ('two', 12381),\n",
       " ('many', 12275),\n",
       " ('good', 12081),\n",
       " ('well', 11997)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_conditional_freq['male'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', 6660),\n",
       " ('one', 6612),\n",
       " ('said', 5675),\n",
       " ('could', 4181),\n",
       " ('time', 4093),\n",
       " ('go', 3370),\n",
       " ('god', 3276),\n",
       " ('little', 2966),\n",
       " ('mr', 2911),\n",
       " ('good', 2824),\n",
       " ('day', 2801),\n",
       " ('people', 2730),\n",
       " ('lord', 2728),\n",
       " ('well', 2716),\n",
       " ('came', 2691),\n",
       " ('old', 2688),\n",
       " ('see', 2648),\n",
       " ('upon', 2646),\n",
       " ('many', 2625),\n",
       " ('went', 2607)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_conditional_freq['female'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
